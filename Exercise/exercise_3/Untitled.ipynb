{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 3, 32, 32)\n",
      "Train size: 60000\n",
      "Val size: 60000\n",
      "Test size: 60000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Data utility functions.\"\"\"\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import _pickle as pickle\n",
    "\n",
    "# pylint: disable=C0326\n",
    "SEG_LABELS_LIST = [\n",
    "    {\"id\": -1, \"name\": \"void\",       \"rgb_values\": [0,   0,    0]},\n",
    "    {\"id\": 0,  \"name\": \"building\",   \"rgb_values\": [128, 0,    0]},\n",
    "    {\"id\": 1,  \"name\": \"grass\",      \"rgb_values\": [0,   128,  0]},\n",
    "    {\"id\": 2,  \"name\": \"tree\",       \"rgb_values\": [128, 128,  0]},\n",
    "    {\"id\": 3,  \"name\": \"cow\",        \"rgb_values\": [0,   0,    128]},\n",
    "    {\"id\": 4,  \"name\": \"horse\",      \"rgb_values\": [128, 0,    128]},\n",
    "    {\"id\": 5,  \"name\": \"sheep\",      \"rgb_values\": [0,   128,  128]},\n",
    "    {\"id\": 6,  \"name\": \"sky\",        \"rgb_values\": [128, 128,  128]},\n",
    "    {\"id\": 7,  \"name\": \"mountain\",   \"rgb_values\": [64,  0,    0]},\n",
    "    {\"id\": 8,  \"name\": \"airplane\",   \"rgb_values\": [192, 0,    0]},\n",
    "    {\"id\": 9,  \"name\": \"water\",      \"rgb_values\": [64,  128,  0]},\n",
    "    {\"id\": 10, \"name\": \"face\",       \"rgb_values\": [192, 128,  0]},\n",
    "    {\"id\": 11, \"name\": \"car\",        \"rgb_values\": [64,  0,    128]},\n",
    "    {\"id\": 12, \"name\": \"bicycle\",    \"rgb_values\": [192, 0,    128]},\n",
    "    {\"id\": 13, \"name\": \"flower\",     \"rgb_values\": [64,  128,  128]},\n",
    "    {\"id\": 14, \"name\": \"sign\",       \"rgb_values\": [192, 128,  128]},\n",
    "    {\"id\": 15, \"name\": \"bird\",       \"rgb_values\": [0,   64,   0]},\n",
    "    {\"id\": 16, \"name\": \"book\",       \"rgb_values\": [128, 64,   0]},\n",
    "    {\"id\": 17, \"name\": \"chair\",      \"rgb_values\": [0,   192,  0]},\n",
    "    {\"id\": 18, \"name\": \"road\",       \"rgb_values\": [128, 64,   128]},\n",
    "    {\"id\": 19, \"name\": \"cat\",        \"rgb_values\": [0,   192,  128]},\n",
    "    {\"id\": 20, \"name\": \"dog\",        \"rgb_values\": [128, 192,  128]},\n",
    "    {\"id\": 21, \"name\": \"body\",       \"rgb_values\": [64,  64,   0]},\n",
    "    {\"id\": 22, \"name\": \"boat\",       \"rgb_values\": [192, 64,   0]}]\n",
    "\n",
    "\n",
    "def label_img_to_rgb(label_img):\n",
    "    label_img = np.squeeze(label_img)\n",
    "    labels = np.unique(label_img)\n",
    "    label_infos = [l for l in SEG_LABELS_LIST if l['id'] in labels]\n",
    "\n",
    "    label_img_rgb = np.array([label_img,\n",
    "                              label_img,\n",
    "                              label_img]).transpose(1,2,0)\n",
    "    for l in label_infos:\n",
    "        mask = label_img == l['id']\n",
    "        label_img_rgb[mask] = l['rgb_values']\n",
    "\n",
    "    return label_img_rgb.astype(np.uint8)\n",
    "\n",
    "\n",
    "class SegmentationData(data.Dataset):\n",
    "\n",
    "    def __init__(self, image_paths_file):\n",
    "        self.root_dir_name = os.path.dirname(image_paths_file)\n",
    "\n",
    "        with open(image_paths_file) as f:\n",
    "            self.image_names = f.read().splitlines()\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, slice):\n",
    "            # get the start, stop, and step from the slice\n",
    "            return [self[ii] for ii in range(*key.indices(len(self)))]\n",
    "        elif isinstance(key, int):\n",
    "            # handle negative indices\n",
    "            if key < 0:\n",
    "                key += len(self)\n",
    "            if key < 0 or key >= len(self):\n",
    "                raise IndexError(\"The index (%d) is out of range.\" % key)\n",
    "            # get the data from direct index\n",
    "            return self.get_item_from_index(key)\n",
    "        else:\n",
    "            raise TypeError(\"Invalid argument type.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def get_item_from_index(self, index):\n",
    "        to_tensor = transforms.ToTensor()\n",
    "        img_id = self.image_names[index].replace('.bmp', '')\n",
    "\n",
    "        img = Image.open(os.path.join(self.root_dir_name,\n",
    "                                      'images',\n",
    "                                      img_id + '.bmp')).convert('RGB')\n",
    "        center_crop = transforms.CenterCrop(240)\n",
    "        img = center_crop(img)\n",
    "        img = to_tensor(img)\n",
    "\n",
    "        target = Image.open(os.path.join(self.root_dir_name,\n",
    "                                         'targets',\n",
    "                                         img_id + '_GT.bmp'))\n",
    "        target = center_crop(target)\n",
    "        target = np.array(target, dtype=np.int64)\n",
    "\n",
    "        target_labels = target[..., 0]\n",
    "        for label in SEG_LABELS_LIST:\n",
    "            mask = np.all(target == label['rgb_values'], axis=2)\n",
    "            target_labels[mask] = label['id']\n",
    "\n",
    "        target_labels = torch.from_numpy(target_labels.copy())\n",
    "\n",
    "        return img, target_labels\n",
    "\n",
    "\n",
    "class OverfitSampler(object):\n",
    "    \"\"\"\n",
    "    Sample dataset to overfit.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "class CIFAR10Data(data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.X[index]\n",
    "        label = self.y[index]\n",
    "\n",
    "        img = torch.from_numpy(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "\n",
    "def get_CIFAR10_data(num_training=48000, num_validation=1000, num_test=1000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for classifiers. These are the same steps as we used for the SVM, but\n",
    "    condensed to a single function.\n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'datasets/'\n",
    "    X, y = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    # Our training set will be the first num_train points from the original\n",
    "    # training set.\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X[mask]\n",
    "    y_train = y[mask]\n",
    "\n",
    "    # Our validation set will be num_validation points from the original\n",
    "    # training set.\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X[mask]\n",
    "    y_val = y[mask]\n",
    "\n",
    "    # We use a small subset of the training set as our test set.\n",
    "    mask = list(range(num_training + num_validation,\n",
    "                      num_training + num_validation + num_test))\n",
    "    X_test = X[mask]\n",
    "    y_test = y[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    # Transpose so that channels come first\n",
    "    X_train = X_train.transpose(0, 3, 1, 2).copy()\n",
    "    X_val = X_val.transpose(0, 3, 1, 2).copy()\n",
    "    X_test = X_test.transpose(0, 3, 1, 2).copy()\n",
    "\n",
    "    # Package data into a dictionary\n",
    "    return {\n",
    "        'X_train': X_train, 'y_train': y_train,\n",
    "        'X_val': X_val, 'y_val': y_val,\n",
    "        'X_test': X_test, 'y_test': y_test,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_CIFAR10_datasets(num_training=60000, num_validation=1000,\n",
    "                         num_test=1000, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Load and preprocess the CIFAR-10 dataset.\n",
    "    \"\"\"\n",
    "    paths = ['datasets/cifar-10-batches-py/data_batch_1', 'datasets/cifar-10-batches-py/data_batch_2', 'datasets/cifar-10-batches-py/data_batch_3'\n",
    "            , 'datasets/cifar-10-batches-py/data_batch_4', 'datasets/cifar-10-batches-py/data_batch_5']\n",
    "    \n",
    "    path_test = 'datasets/cifar-10-batches-py/test_batch'\n",
    "    \n",
    "    with open(path_test, 'rb') as f:\n",
    "            datadict = pickle.load(f, encoding='latin1')\n",
    "            X = np.array(datadict['data'])\n",
    "            y = np.array(datadict['labels'])\n",
    "            X = X.reshape(-1, 3, 32, 32).astype(dtype)\n",
    "            \n",
    "    for path in paths:\n",
    "        with open(path, 'rb') as f:\n",
    "            datadict = pickle.load(f, encoding='latin1')\n",
    "            X_ = np.array(datadict['data'])\n",
    "            y_ = np.array(datadict['labels'])\n",
    "            X_ = X_.reshape(-1, 3, 32, 32).astype(dtype)\n",
    "            X = np.concatenate((X, X_), axis=0)\n",
    "            y = np.concatenate((y, y_), axis=0)\n",
    "\n",
    "    print(y.shape)\n",
    "    print(X.shape)\n",
    "    X /= 255.0\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X, axis=0)\n",
    "    X -= mean_image\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training)\n",
    "    X_train = X[mask]\n",
    "    y_train = y[mask]\n",
    "    #mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X[mask]\n",
    "    y_val = y[mask]\n",
    "    #mask = range(num_training + num_validation,\n",
    "    #             num_training + num_validation + num_test)\n",
    "    \n",
    "    X_test = X[mask]\n",
    "    y_test = y[mask]\n",
    "\n",
    "    return (CIFAR10Data(X_train, y_train),\n",
    "            CIFAR10Data(X_val, y_val),\n",
    "            CIFAR10Data(X_test, y_test),\n",
    "            mean_image)\n",
    "\n",
    "\n",
    "def scoring_function(x, lin_exp_boundary, doubling_rate):\n",
    "    assert np.all([x >= 0, x <= 1])\n",
    "    score = np.zeros(x.shape)\n",
    "    lin_exp_boundary = lin_exp_boundary\n",
    "    linear_region = np.logical_and(x > 0.1, x <= lin_exp_boundary)\n",
    "    exp_region = np.logical_and(x > lin_exp_boundary, x <= 1)\n",
    "    score[linear_region] = 100.0 * x[linear_region]\n",
    "    c = doubling_rate\n",
    "    a = 100.0 * lin_exp_boundary / np.exp(lin_exp_boundary * np.log(2) / c)\n",
    "    b = np.log(2.0) / c\n",
    "    score[exp_region] = a * np.exp(b * x[exp_region])\n",
    "    return score\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" Returns relative error \"\"\"\n",
    "    assert x.shape == y.shape, \"tensors do not have the same shape. %s != %s\" % (x.shape, y.shape)\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "train_data, val_data, test_data, mean_image = get_CIFAR10_datasets()\n",
    "\n",
    "print(\"Train size: %i\" % len(train_data))\n",
    "print(\"Val size: %i\" % len(val_data))\n",
    "print(\"Test size: %i\" % len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,3) (2,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-cfb4e61afd30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,3) (2,3) "
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "b = np.array([[1,2,3], [7,8,9]])\n",
    "a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
