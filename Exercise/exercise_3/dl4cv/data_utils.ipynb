{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Data utility functions.\"\"\"\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import _pickle as pickle\n",
    "\n",
    "# pylint: disable=C0326\n",
    "SEG_LABELS_LIST = [\n",
    "    {\"id\": -1, \"name\": \"void\",       \"rgb_values\": [0,   0,    0]},\n",
    "    {\"id\": 0,  \"name\": \"building\",   \"rgb_values\": [128, 0,    0]},\n",
    "    {\"id\": 1,  \"name\": \"grass\",      \"rgb_values\": [0,   128,  0]},\n",
    "    {\"id\": 2,  \"name\": \"tree\",       \"rgb_values\": [128, 128,  0]},\n",
    "    {\"id\": 3,  \"name\": \"cow\",        \"rgb_values\": [0,   0,    128]},\n",
    "    {\"id\": 4,  \"name\": \"horse\",      \"rgb_values\": [128, 0,    128]},\n",
    "    {\"id\": 5,  \"name\": \"sheep\",      \"rgb_values\": [0,   128,  128]},\n",
    "    {\"id\": 6,  \"name\": \"sky\",        \"rgb_values\": [128, 128,  128]},\n",
    "    {\"id\": 7,  \"name\": \"mountain\",   \"rgb_values\": [64,  0,    0]},\n",
    "    {\"id\": 8,  \"name\": \"airplane\",   \"rgb_values\": [192, 0,    0]},\n",
    "    {\"id\": 9,  \"name\": \"water\",      \"rgb_values\": [64,  128,  0]},\n",
    "    {\"id\": 10, \"name\": \"face\",       \"rgb_values\": [192, 128,  0]},\n",
    "    {\"id\": 11, \"name\": \"car\",        \"rgb_values\": [64,  0,    128]},\n",
    "    {\"id\": 12, \"name\": \"bicycle\",    \"rgb_values\": [192, 0,    128]},\n",
    "    {\"id\": 13, \"name\": \"flower\",     \"rgb_values\": [64,  128,  128]},\n",
    "    {\"id\": 14, \"name\": \"sign\",       \"rgb_values\": [192, 128,  128]},\n",
    "    {\"id\": 15, \"name\": \"bird\",       \"rgb_values\": [0,   64,   0]},\n",
    "    {\"id\": 16, \"name\": \"book\",       \"rgb_values\": [128, 64,   0]},\n",
    "    {\"id\": 17, \"name\": \"chair\",      \"rgb_values\": [0,   192,  0]},\n",
    "    {\"id\": 18, \"name\": \"road\",       \"rgb_values\": [128, 64,   128]},\n",
    "    {\"id\": 19, \"name\": \"cat\",        \"rgb_values\": [0,   192,  128]},\n",
    "    {\"id\": 20, \"name\": \"dog\",        \"rgb_values\": [128, 192,  128]},\n",
    "    {\"id\": 21, \"name\": \"body\",       \"rgb_values\": [64,  64,   0]},\n",
    "    {\"id\": 22, \"name\": \"boat\",       \"rgb_values\": [192, 64,   0]}]\n",
    "\n",
    "\n",
    "def label_img_to_rgb(label_img):\n",
    "    label_img = np.squeeze(label_img)\n",
    "    labels = np.unique(label_img)\n",
    "    label_infos = [l for l in SEG_LABELS_LIST if l['id'] in labels]\n",
    "\n",
    "    label_img_rgb = np.array([label_img,\n",
    "                              label_img,\n",
    "                              label_img]).transpose(1,2,0)\n",
    "    for l in label_infos:\n",
    "        mask = label_img == l['id']\n",
    "        label_img_rgb[mask] = l['rgb_values']\n",
    "\n",
    "    return label_img_rgb.astype(np.uint8)\n",
    "\n",
    "\n",
    "class SegmentationData(data.Dataset):\n",
    "\n",
    "    def __init__(self, image_paths_file):\n",
    "        self.root_dir_name = os.path.dirname(image_paths_file)\n",
    "\n",
    "        with open(image_paths_file) as f:\n",
    "            self.image_names = f.read().splitlines()\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, slice):\n",
    "            # get the start, stop, and step from the slice\n",
    "            return [self[ii] for ii in range(*key.indices(len(self)))]\n",
    "        elif isinstance(key, int):\n",
    "            # handle negative indices\n",
    "            if key < 0:\n",
    "                key += len(self)\n",
    "            if key < 0 or key >= len(self):\n",
    "                raise IndexError(\"The index (%d) is out of range.\" % key)\n",
    "            # get the data from direct index\n",
    "            return self.get_item_from_index(key)\n",
    "        else:\n",
    "            raise TypeError(\"Invalid argument type.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def get_item_from_index(self, index):\n",
    "        to_tensor = transforms.ToTensor()\n",
    "        img_id = self.image_names[index].replace('.bmp', '')\n",
    "\n",
    "        img = Image.open(os.path.join(self.root_dir_name,\n",
    "                                      'images',\n",
    "                                      img_id + '.bmp')).convert('RGB')\n",
    "        center_crop = transforms.CenterCrop(240)\n",
    "        img = center_crop(img)\n",
    "        img = to_tensor(img)\n",
    "\n",
    "        target = Image.open(os.path.join(self.root_dir_name,\n",
    "                                         'targets',\n",
    "                                         img_id + '_GT.bmp'))\n",
    "        target = center_crop(target)\n",
    "        target = np.array(target, dtype=np.int64)\n",
    "\n",
    "        target_labels = target[..., 0]\n",
    "        for label in SEG_LABELS_LIST:\n",
    "            mask = np.all(target == label['rgb_values'], axis=2)\n",
    "            target_labels[mask] = label['id']\n",
    "\n",
    "        target_labels = torch.from_numpy(target_labels.copy())\n",
    "\n",
    "        return img, target_labels\n",
    "\n",
    "\n",
    "class OverfitSampler(object):\n",
    "    \"\"\"\n",
    "    Sample dataset to overfit.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "class CIFAR10Data(data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.X[index]\n",
    "        label = self.y[index]\n",
    "\n",
    "        img = torch.from_numpy(img)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "\n",
    "def get_CIFAR10_data(num_training=48000, num_validation=1000, num_test=1000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for classifiers. These are the same steps as we used for the SVM, but\n",
    "    condensed to a single function.\n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'datasets/'\n",
    "    X, y = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    # Our training set will be the first num_train points from the original\n",
    "    # training set.\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X[mask]\n",
    "    y_train = y[mask]\n",
    "\n",
    "    # Our validation set will be num_validation points from the original\n",
    "    # training set.\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X[mask]\n",
    "    y_val = y[mask]\n",
    "\n",
    "    # We use a small subset of the training set as our test set.\n",
    "    mask = list(range(num_training + num_validation,\n",
    "                      num_training + num_validation + num_test))\n",
    "    X_test = X[mask]\n",
    "    y_test = y[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    # Transpose so that channels come first\n",
    "    X_train = X_train.transpose(0, 3, 1, 2).copy()\n",
    "    X_val = X_val.transpose(0, 3, 1, 2).copy()\n",
    "    X_test = X_test.transpose(0, 3, 1, 2).copy()\n",
    "\n",
    "    # Package data into a dictionary\n",
    "    return {\n",
    "        'X_train': X_train, 'y_train': y_train,\n",
    "        'X_val': X_val, 'y_val': y_val,\n",
    "        'X_test': X_test, 'y_test': y_test,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_CIFAR10_datasets(num_training=48000, num_validation=1000,\n",
    "                         num_test=1000, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Load and preprocess the CIFAR-10 dataset.\n",
    "    \"\"\"\n",
    "    path = 'datasets/cifar10_train.p'\n",
    "    with open(path, 'rb') as f:\n",
    "        datadict = pickle.load(f, encoding='latin1')\n",
    "        X = np.array(datadict['data'])\n",
    "        y = np.array(datadict['labels'])\n",
    "        X = X.reshape(-1, 3, 32, 32).astype(dtype)\n",
    "\n",
    "    X /= 255.0\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X, axis=0)\n",
    "    X -= mean_image\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training)\n",
    "    X_train = X[mask]\n",
    "    y_train = y[mask]\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X[mask]\n",
    "    y_val = y[mask]\n",
    "    mask = range(num_training + num_validation,\n",
    "                 num_training + num_validation + num_test)\n",
    "    X_test = X[mask]\n",
    "    y_test = y[mask]\n",
    "\n",
    "    return (CIFAR10Data(X_train, y_train),\n",
    "            CIFAR10Data(X_val, y_val),\n",
    "            CIFAR10Data(X_test, y_test),\n",
    "            mean_image)\n",
    "\n",
    "\n",
    "def scoring_function(x, lin_exp_boundary, doubling_rate):\n",
    "    assert np.all([x >= 0, x <= 1])\n",
    "    score = np.zeros(x.shape)\n",
    "    lin_exp_boundary = lin_exp_boundary\n",
    "    linear_region = np.logical_and(x > 0.1, x <= lin_exp_boundary)\n",
    "    exp_region = np.logical_and(x > lin_exp_boundary, x <= 1)\n",
    "    score[linear_region] = 100.0 * x[linear_region]\n",
    "    c = doubling_rate\n",
    "    a = 100.0 * lin_exp_boundary / np.exp(lin_exp_boundary * np.log(2) / c)\n",
    "    b = np.log(2.0) / c\n",
    "    score[exp_region] = a * np.exp(b * x[exp_region])\n",
    "    return score\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" Returns relative error \"\"\"\n",
    "    assert x.shape == y.shape, \"tensors do not have the same shape. %s != %s\" % (x.shape, y.shape)\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
