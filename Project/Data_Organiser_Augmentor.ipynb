{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "/*\n",
    "** Data_organiser_augmentor.ipynb\n",
    "** This file has been used to filter appropriate data from original CK+ dataset based on \n",
    "** availability of corresponding label for respective class images.\n",
    "** Split the filter data into three different set (Training(80%), Testing(10%) and Validation(10%))\n",
    "** and put the in different folder.\n",
    "** Later Augment only Training dataset.(only flip augmentation has been used.)\n",
    "**\n",
    "** @author: Abhijeet Parida, Jyotirmay Senapati\n",
    "** @Date: 27th January, 2018\n",
    "** @Copyright: Facial Expression Prediction, DL4CV project, Winter Sem, 2018\n",
    "*/\n",
    "'''\n",
    "\n",
    "# Importing modules\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import cv2 \n",
    "import glob\n",
    "from shutil import copyfile, rmtree, copytree\n",
    "import utils.img_allign_expnet as iae\n",
    "\n",
    "emo_dict = {\"neutral\":0, \"anger\":1, \"contempt\":2, \"disgust\":3, \"fear\":4, \"happy\":5, \"sadness\":6, \"surprise\":7 }\n",
    "emo_list = [\"neutral\", \"anger\", \"contempt\", \"disgust\", \"fear\", \"happy\", \"sadness\", \"surprise\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating required folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Uncomment if respective files are not present and need to be created.\n",
    "#root = \"data/alligned\"\n",
    "#os.makedirs('%s'%root)\n",
    "\n",
    "#for emotion in emo_list:\n",
    "#    os.makedirs('%s/%s/'%(f\"{root}\",emotion)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying filtered images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# original_data + label (filtering)==> filtered_data (allignment)==> alligned (splitting)==> set (augmentation)==> set \n",
    "\n",
    "def get_filtered_data():\n",
    "    data_folder = \"data/original_data\"\n",
    "    label_folder = \"data/labels\"\n",
    "    destination_folder = \"data/filtered_data\"\n",
    "\n",
    "    participants = glob.glob(f\"{data_folder}/*\")\n",
    "\n",
    "    ## Selecting 3 peak expressions and one neutral from each time frame in the CK+ data set where \n",
    "    ## corresponding label is available.\n",
    "    ## Thereafter moving them to their respective emotion folder.\n",
    "    for x in participants:\n",
    "        part = \"%s\" %x[-4:] #store current participant number\n",
    "        for sessions in glob.glob(\"%s//*\" %x): #Store list of sessions for current participant\n",
    "            for files in glob.glob(\"%s//*\" %sessions):\n",
    "                current_session = sessions[-3:]\n",
    "                label_file = files.split(\".\")[0].split(\"/\")[4]\n",
    "                label_file = label_file+\"_emotion.txt\"\n",
    "                label_ = f\"{label_folder}/{part}/{current_session}/{label_file}\"\n",
    "                #if label_ == \"data/labels/S014/001/S014_001_00000029_emotion.txt\":\n",
    "                    \n",
    "                if os.path.isfile(label_):\n",
    "                    print(f\"file exist:{label_}\")\n",
    "                    file = open(label_, 'r')\n",
    "\n",
    "                    #emotions are encoded as a float, readline as float, then convert to integer.\n",
    "                    emotion = int(float(file.readline()))\n",
    "\n",
    "                    #get path for last three images in sequence, which contains the pick expressions\n",
    "                    sourcefile_emotion_frame1 = sorted(glob.glob(f\"{data_folder}/%s/%s/*\" %(part, current_session)))[-1] \n",
    "                    sourcefile_emotion_frame2 = sorted(glob.glob(f\"{data_folder}/%s/%s/*\" %(part, current_session)))[-2]\n",
    "                    sourcefile_emotion_frame3 = sorted(glob.glob(f\"{data_folder}/%s/%s/*\" %(part, current_session)))[-3]\n",
    "\n",
    "                    sourcefile_neutral = sorted(glob.glob(f\"{data_folder}/%s/%s/*\" %(part, current_session)))[0]\n",
    "\n",
    "                    #Generate respective destinations path to put respective images\n",
    "                    dest_emot_frame1 = f\"{destination_folder}/%s/%s\" %(emo_list[emotion], sourcefile_emotion_frame1[-21:]) \n",
    "                    dest_emot_frame2 = f\"{destination_folder}/%s/%s\" %(emo_list[emotion], sourcefile_emotion_frame2[-21:]) \n",
    "                    dest_emot_frame3 = f\"{destination_folder}/%s/%s\" %(emo_list[emotion], sourcefile_emotion_frame3[-21:]) \n",
    "\n",
    "                    dest_neut = f\"{destination_folder}/neutral/%s\" %sourcefile_neutral[-21:]\n",
    "\n",
    "                    #Copy file\n",
    "                    copyfile(sourcefile_neutral, dest_neut)\n",
    "                    copyfile(sourcefile_emotion_frame1, dest_emot_frame1)\n",
    "                    copyfile(sourcefile_emotion_frame2, dest_emot_frame2)\n",
    "                    copyfile(sourcefile_emotion_frame3, dest_emot_frame3)\n",
    "                else:\n",
    "                    print(\"no label file for corresponding image file, skipping it.\")\n",
    "                    \n",
    "get_filtered_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(root, imgs, labels):\n",
    "    paths = [[f\"{root}/{i}\", i] for i in emo_dict.keys()]\n",
    "    for path in paths:\n",
    "        for augmneted_file in os.listdir(path[0]):\n",
    "            img_path = os.path.join(path[0], augmneted_file)\n",
    "            try:\n",
    "                if os.path.isfile(img_path):\n",
    "                    imgs.append(img_path)\n",
    "                    labels.append(emo_dict[path[1]])\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return imgs, labels\n",
    "\n",
    "img_paths, labels = get_data(\"data/filtered_data\", [], [])\n",
    "\n",
    "for img_path, label in zip(img_paths, labels):\n",
    "        iae.img_align(img_path, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting filtered data into training, testing and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Getting all images with its label in a list. Converting it to numpy array for later separation.\n",
    "imgs, labels = get_data(\"data/alligned\", [], [])\n",
    "\n",
    "# Shuffling of data to get random emotions into every set.\n",
    "dataset = list(zip(imgs, labels))\n",
    "shuffle(dataset)\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "## img paths and level separation into train, validate and test set.\n",
    "def split(dataset):\n",
    "    count = len(dataset)\n",
    "\n",
    "    num_training = int(count*0.8) #80% into training\n",
    "    num_validation = int((count-num_training)/2) #10% into validation\n",
    "    num_testing = int((count-num_training)/2)-1 # rest 10# to testing\n",
    "\n",
    "    mask = range(num_training)\n",
    "    X_train = dataset[mask]\n",
    "\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = dataset[mask]\n",
    "\n",
    "    mask = range(num_training + num_validation, \\\n",
    "                 num_training + num_validation + num_testing)\n",
    "    X_test = dataset[mask]\n",
    "\n",
    "    # Copying files to their respective locations. separating them to train, validate and test folder.\n",
    "    all_set = {\"training\": X_train, \"validation\": X_val, \"testing\": X_test}\n",
    "\n",
    "    for key, value in all_set.items():\n",
    "        count_neutral, count_anger, count_contempt, count_disgust = 0, 0, 0, 0\n",
    "        count_fear, count_happy, count_sadness, count_surprise = 0, 0, 0, 0\n",
    "\n",
    "        for img_path in value:\n",
    "            image_name = img_path[0].split(\"/\")[-1]  \n",
    "            dest = f\"data/set/{key}/{emo_list[int(img_path[1])]}/{image_name}\"\n",
    "            if emo_list[int(img_path[1])] == \"neutral\":\n",
    "                count_neutral +=1\n",
    "            if emo_list[int(img_path[1])] == \"anger\":\n",
    "                count_anger +=1\n",
    "            if emo_list[int(img_path[1])] == \"contempt\":\n",
    "                count_contempt +=1\n",
    "            if emo_list[int(img_path[1])] == \"disgust\":\n",
    "                count_disgust +=1\n",
    "            if emo_list[int(img_path[1])] == \"fear\":\n",
    "                count_fear +=1\n",
    "            if emo_list[int(img_path[1])] == \"happy\":\n",
    "                count_happy +=1\n",
    "            if emo_list[int(img_path[1])] == \"sadness\":\n",
    "                count_sadness +=1\n",
    "            if emo_list[int(img_path[1])] == \"surprise\":\n",
    "                count_surprise +=1\n",
    "\n",
    "            img = cv2.imread(img_path[0])\n",
    "\n",
    "            cv2.imwrite(dest, img)\n",
    "\n",
    "        total = count_neutral + count_anger + count_contempt + count_disgust + count_fear \\\n",
    "                + count_happy + count_sadness + count_surprise \n",
    "\n",
    "        print(\"neutral:\", count_neutral, \"anger:\", count_anger, \"contempt:\", count_contempt, \\\n",
    "              \"disgust:\", count_disgust, \"fear:\", count_fear, \"happy:\", count_happy, \"sadness:\",count_sadness,\\\n",
    "              \"surprise:\", count_surprise, \"total:\", total)\n",
    "\n",
    "split(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenting training data set only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment():\n",
    "    for emotion in emo_list:\n",
    "        folder = f\"data/set/training/{emotion}\"\n",
    "        for the_file in os.listdir(folder):\n",
    "            img_path = os.path.join(folder, the_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                original = img.copy()\n",
    "                cv2.imwrite(f\"data/train_augmented/{emotion}/{the_file}\", original)\n",
    "                horizontal_img = cv2.flip( original, 1 )\n",
    "                cv2.imwrite(f\"data/train_augmented/{emotion}/flipped_{the_file}\", horizontal_img)\n",
    "                \n",
    "    rmtree('data/set/training')\n",
    "    copytree(\"data/train_augmented\", 'data/set/training')\n",
    "        \n",
    "augment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset directory content recursively, if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def reset(folder):\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                print(f\"Deleteing {the_file}\")\n",
    "                # Deleting a file inside current folder.\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                print(f\"Moving into {file_path}\")\n",
    "                # Calling the function recursively.\n",
    "                reset(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "reset(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
