{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "/*\n",
    "** Naive_Expnet.ipynb\n",
    "** This file has been used to train a conv-net in phase1 to immitate facenet properties.\n",
    "** In phase2, trained another fully-connected network with conv-net from phase1 to learn human emotions properties.\n",
    "** Also used to find out all matrices for predicted output.\n",
    "** @author: Jyotirmay Senapati, Shayan Ahmad Siddiqui, Abhijeet Parida\n",
    "** @Date: 24th January, 2018\n",
    "** @Copyright: Facial Expression Prediction, DL4CV project, Winter Sem, 2018\n",
    "*/\n",
    "'''\n",
    "\n",
    "## We are working on alligned augmented training set and original+alligned test and validation set present in data/set\n",
    "## folder.\n",
    "\n",
    "# Importing modules\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import os, time \n",
    "import cv2\n",
    "from torch.autograd import Variable\n",
    "import utils.data_loader_expnet as de\n",
    "import utils.solver_expnet as se\n",
    "import utils.model_phase1_expnet as me\n",
    "import utils.model_phase2_expnet as mpe\n",
    "import utils.loadOpenFace as ff\n",
    "import utils.img_allign_expnet as iae\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import itertools\n",
    "\n",
    "emo_dict = {\"neutral\":0, \"anger\":1, \"contempt\":2, \"disgust\":3, \"fear\":4, \"happy\":5, \"sadness\":6, \"surprise\":7 }\n",
    "useCuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReadImage(pathname, label=None, isFacenetData = False, imgAlligned = True): \n",
    "        if imgAlligned:\n",
    "            img = cv2.imread(pathname)\n",
    "        else:\n",
    "            img = iae.img_align(pathname, label)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        img = cv2.resize(img, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "        img = np.transpose(img, (2, 0, 1)) \n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        I_ = torch.from_numpy(img).unsqueeze(0)\n",
    "        if isFacenetData:\n",
    "            if useCuda:\n",
    "                I_ = I_.cuda()\n",
    "        return I_\n",
    "\n",
    "def get_path_and_labels(root, img_paths, labels, num_of_image_per_class=None):\n",
    "    paths = [[f\"{root}/{i}\", i] for i in emo_dict.keys()]\n",
    "    for path in paths:\n",
    "        counter = 0\n",
    "        for augmneted_file in os.listdir(path[0]):\n",
    "            img_path = os.path.join(path[0], augmneted_file)\n",
    "            try:\n",
    "                if os.path.isfile(img_path):\n",
    "                    counter+=1\n",
    "                    img_paths.append(img_path)\n",
    "                    labels.append(emo_dict[path[1]])\n",
    "                    if num_of_image_per_class is not None and counter>num_of_image_per_class:\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return img_paths, labels\n",
    "\n",
    "def load_data(img_paths, visualisation=False):\n",
    "    imgs = []\n",
    "    for img_path in img_paths:\n",
    "        if visualisation:\n",
    "            imgs.append(ReadImage_for_visualisation(img_path, None, True, True))\n",
    "        else:\n",
    "            imgs.append(ReadImage(img_path, None,  True, True))\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running data loading and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Loading data... \")\n",
    "\n",
    "img_paths_train, labels_train = get_path_and_labels(\"data/set/training\", [], [])\n",
    "img_paths_val, labels_val = get_path_and_labels(\"data/set/validation\", [], [])\n",
    "img_paths_test, labels_test = get_path_and_labels(\"data/set/testing\", [], [])\n",
    "imgs_train = load_data(img_paths_train)\n",
    "imgs_val = load_data(img_paths_val)\n",
    "imgs_test = load_data(img_paths_test)\n",
    "\n",
    "print(\"Training : \"+str(len(imgs_train)))\n",
    "print(\"Validation : \"+str(len(imgs_val)))\n",
    "print(\"Test : \"+str(len(imgs_test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ReadImage_for_visualisation(pathname, label=None, isFacenetData = False, imgAlligned = True): \n",
    "        if imgAlligned:\n",
    "            img = cv2.imread(pathname)\n",
    "        else:\n",
    "            img = iae.img_align(pathname, label)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        return img\n",
    "\n",
    "def visualize_data(X, y, classes, samples_per_class = 4):\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    for y_hat, cls in enumerate(classes):\n",
    "        idxs = np.where(y == y_hat)[0]\n",
    "        idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "        for i, idx in enumerate(idxs):\n",
    "            plt_idx = i * num_classes + y_hat + 1\n",
    "            plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "            img = X[idx]\n",
    "\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            if i == 0:\n",
    "                plt.title(cls)\n",
    "    plt.show()\n",
    "    \n",
    "img_paths_visualisation, labels_visualisation = get_path_and_labels(\"data/set/testing\", [], [])\n",
    "imgs_visualisation = np.array(load_data(img_paths_visualisation, True))\n",
    "visualize_data(imgs_visualisation, np.array(labels_visualisation), classes = list(emo_dict), samples_per_class = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to load the pretrained facenet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareOpenFace(useCuda=True, gpuDevice=0, useMultiGPU=False):\n",
    "    print(\"Preparing openface object\")\n",
    "    model = ff.netOpenFace(useCuda, gpuDevice)\n",
    "    model.load_state_dict(torch.load(os.path.join('./utils/pretrained_model/', 'openface.pth')))\n",
    "    if useMultiGPU:\n",
    "        model = nn.DataParallel(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running facenet and obtaining training set scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running openface network.\n",
    "nof = prepareOpenFace()\n",
    "nof = nof.eval()\n",
    "\n",
    "I = np.reshape(np.array(range(96 * 96), dtype=np.float32) * 0.01, (1,96,96))\n",
    "I = np.concatenate([I, I, I], axis=0)\n",
    "I_ = torch.from_numpy(I).unsqueeze(0)\n",
    "I_ = I_.cuda()\n",
    "    \n",
    "openface_out =  Variable(torch.Tensor(len(imgs_train),736, 1, 1))\n",
    "\n",
    "I_ = torch.cat(imgs_train, 0)\n",
    "start = time.time()\n",
    "for idx, x in enumerate(I_):\n",
    "    x = Variable(x, volatile=True)  \n",
    "    out = nof(x.view(-1, 3, 96, 96))\n",
    "    openface_out[idx] = out[0]\n",
    "\n",
    "I_val_ = torch.cat(imgs_val, 0)\n",
    "I_val_ = Variable(I_val_, volatile=True)  \n",
    "start = time.time()\n",
    "openface_out_val_ = nof(I_val_)\n",
    "torch.cuda.empty_cache()    \n",
    "print(\"  + Forward pass took {} seconds.\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1 : Conv layers training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function for Exp Net Conv layer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_expnet(output, target):\n",
    "    diff = (output-target).view(-1)\n",
    "    diff_normed = torch.norm(diff, 2, 0) ** 2\n",
    "    ls = torch.sum(diff_normed) / output.size(0)\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating batch loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_p1 = de.CKData(np.array(imgs_train, dtype=np.object), openface_out.data)\n",
    "val_data_p1 = de.CKData(np.array(imgs_val, dtype=np.object), openface_out_val_.data)\n",
    "train_loader_p1 = torch.utils.data.DataLoader(train_data_p1, batch_size=50, shuffle=True)\n",
    "val_loader_p1 = torch.utils.data.DataLoader(val_data_p1, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Expnet Conv layers training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_p1 = me.ExpNet(useCuda=True, gpuDevice=0)\n",
    "solver_p1 = se.Solver(optim_args={\"lr\": 1e-3}, loss_func=loss_expnet)\n",
    "solver_p1.train(model_p1, train_loader_p1, val_loader_p1, log_nth=1, num_epochs=100)\n",
    "torch.save(model_p1.state_dict(), 'model/expnet_interim.pt')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(solver_p1.train_loss_history, 'o')\n",
    "plt.plot(np.asarray(solver_p1.val_loss_history).squeeze(), 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2 : Training classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-entropy loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_loss(x, y): \n",
    "    N = x.size(0)\n",
    "    loss = 0\n",
    "    max_vals = torch.max(x, 1)[0]\n",
    "    for i, ipt in enumerate(x):\n",
    "        diff = x[i] - max_vals[i]\n",
    "        probs = torch.exp(diff)\n",
    "        probs /= torch.sum(probs)\n",
    "        loss += torch.log(probs[y[i].data[0]])\n",
    "        \n",
    "    loss = -(loss / N)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating batch loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_p2 = de.CKData(np.array(imgs_train, dtype=np.object), torch.LongTensor(labels_train))\n",
    "val_data_p2 = de.CKData(np.array(imgs_val, dtype=np.object), torch.LongTensor(labels_val))\n",
    "\n",
    "train_loader_p2 = torch.utils.data.DataLoader(train_data_p2, batch_size=50, shuffle=True)\n",
    "val_loader_p2 = torch.utils.data.DataLoader(val_data_p2, batch_size=50, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperparameter for phase2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrs = [0.001, 0.0005, 0.0001, 0.002]\n",
    "wds = [0.01, 0.02, 0.005, 0.001]\n",
    "models = []\n",
    "\n",
    "\n",
    "for lr in lrs: \n",
    "    for wd in wds:\n",
    "        print(\"learning rate:\", lr, \"Weight_decay:\", wd)\n",
    "        model_p2 = mpe.ExpNet_p2(useCuda=True, gpuDevice=0)\n",
    "        solver_p2 = se.Solver(optim_args={\"lr\": lr, \"weight_decay\": wd}, loss_func=softmax_loss)\n",
    "        solver_p2.train(model_p2, train_loader_p2, val_loader_p2, log_nth=1, num_epochs=100, phase2 = True)\n",
    "        models.append([lr, wd, model_p2, solver_p2])\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting best model based on Test_Set Accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_acc(test_data, model_):\n",
    "    model_ = \n",
    "    out = []\n",
    "\n",
    "    for i, x in enumerate(test_data.X):\n",
    "        test_output = model_(Variable(x))\n",
    "        max_val, idx = torch.max(test_output, 1)\n",
    "        out.append(idx.data.cpu().numpy()[0])\n",
    "\n",
    "    targets = []\n",
    "    for i in test_data.y:\n",
    "        targets.append(i)\n",
    "\n",
    "    targets = np.array(targets)\n",
    "    out = np.array(out)\n",
    "    targets_mask = targets >= 0\n",
    "    test_scores = np.mean((out == targets)[targets_mask])\n",
    "    test_acc= np.mean(test_scores)\n",
    "    print(\"Test_set_accuracy:\", test_acc)\n",
    "    return test_acc, out\n",
    "\n",
    "\n",
    "img_paths_test, labels_test = get_path_and_labels(\"data/set/testing\", [], [])\n",
    "imgs_test = []\n",
    "for img_path_test in img_paths_test:\n",
    "    imgs_test.append(ReadImage(img_path_test, None,  True, True))\n",
    "\n",
    "# Best 4 model which have test set accuracy greater than 97%\n",
    "best_model = []\n",
    "for model in models:\n",
    "    print(\"Learning Rate:\", model[0], \"weight_decay:\", model[1])\n",
    "    \n",
    "    solver_p2 = model[3]\n",
    "    acc, out = get_test_acc(de.CKData(np.array(imgs_test, dtype=np.object), torch.LongTensor(labels_test)), model[2])\n",
    "    \n",
    "    if acc > 0.10:\n",
    "        model.append(acc)\n",
    "        best_model.append(model)\n",
    "        \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.title(\"lr:\"+str(model[0])+\" dr:\"+str(model[1])+\" acc:\"+str(acc))\n",
    "    plt.plot(solver_p2.train_loss_history, '-o')\n",
    "    plt.plot(np.asarray(solver_p2.val_loss_history).squeeze(), '-o')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('loss')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(solver_p2.train_acc_history, '-o')\n",
    "    plt.plot(solver_p2.val_acc_history, '-o')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    \n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the classifier training with tuned hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_p2 = mpe.ExpNet_p2(useCuda=True, gpuDevice=0)\n",
    "solver_p2 = se.Solver(optim_args={\"lr\": 0.002, \"weight_decay\": 0.005}, loss_func=softmax_loss)\n",
    "solver_p2.train(model_p2, train_loader_p2, val_loader_p2, log_nth=1, num_epochs=100, phase2 = True)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation loss and accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(solver_p2.train_loss_history, '-o')\n",
    "plt.plot(np.asarray(solver_p2.val_loss_history).squeeze(), '-o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(solver_p2.train_acc_history, '-o')\n",
    "plt.plot(solver_p2.val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc, out = get_test_acc(de.CKData(np.array(imgs_test, dtype=np.object), torch.LongTensor(labels_test)), model_p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model_p1.state_dict(), 'model/expnet_p1.pt')\n",
    "torch.save(model_p2.state_dict(), 'model/expnet_p2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = list(emo_dict)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "y_pred, y_test = out, labels_test\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(truth, pred, average=\"macro\"):\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "\n",
    "    truth = lb.transform(truth)\n",
    "    pred = lb.transform(pred)\n",
    "\n",
    "    return roc_auc_score(truth, pred, average=average)\n",
    "\n",
    "print(multiclass_roc_auc_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
